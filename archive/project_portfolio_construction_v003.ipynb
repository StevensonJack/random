{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackstevenson/CQF/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# database\n",
    "import yfinance as yf\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "# visualisation\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "from matplotlib.patches import Patch\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.style.use('fivethirtyeight')\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  12 of 12 completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3492"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the database\n",
    "\n",
    "# # download (only need close)\n",
    "df = yf.download('IYE IYM IYJ IYC IYK IYH IYF IYW IYZ IDU IYR ^IRX', start='2010-09-24')['Close']\n",
    "\n",
    "# What are the 11 GICS sectors\n",
    "# Energy - iShares U.S. Energy ETF (IYE)\n",
    "# Materials - iShares U.S. Materials ETF (IYM)\n",
    "# Industrials - iShares U.S. Industrials ETF (IYJ)\n",
    "# Consumer Discretionary - iShares U.S. Consumer Disc ETF (IYC)\n",
    "# Consumer Staples - iShares U.S. Consumer Staples ETF (IYK)\n",
    "# Health Care - iShares U.S. Healthcare ETF (IYH)\n",
    "# Financials - iShares U.S. Financials ETF (IYF)\n",
    "# Information Technology - iShares U.S. Technology ETF (IYW)\n",
    "# Communication Services - iShares U.S. Telecom ETF (IYZ)\n",
    "# Utilities - iShares U.S. Utilities ETF (IDU)\n",
    "# Real Estate - iShares US Real Estate ETF (IYR)\n",
    "\n",
    "# # reset index\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "# # create our engine\n",
    "engine = create_engine(\"sqlite:///project_portfolio.db\")\n",
    "\n",
    "# # if_exits will overwrite the pre-existing table\n",
    "df.to_sql('portfolio_data', engine, if_exists='replace', index=False)\n",
    "\n",
    "# # we use this to inspect our data beforehand\n",
    "# inspector = inspect(engine)\n",
    "\n",
    "# table_names = inspector.get_table_names()\n",
    "\n",
    "# print(table_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quotes\n",
    "\n",
    "BLack Litterman (1990)\n",
    "\n",
    "'Our model does not assume thatthe world is always at CAPM equilibrium, but rather that when ex-pected returns move away from their equilibrium values, imbal-ances in marketswill tend to pushthem back'\n",
    "\n",
    "'The investor's benchmark defines the point of origin for measuring this risk. In other words, it represents the minimum-risk portfolio.'\n",
    "\n",
    "The appropriate measure of risk is the tracking error. \n",
    "\n",
    "#### Idzorek\n",
    "\n",
    "'In the absence of constraints, the Black-Litterman model only recommends a departure from an asset’s market capitalization weight if it is the subject of a view. ' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. What is the Black-Litterman Portfolio\n",
    "\n",
    "The initial formulation of the Black-Litterman model for Portfolio construction was described in the 1992 paper. The paper described an intuitive solution by combining the mean-variance opitimisation framework of Markowitz and the capital asset pricing model (CAPM) of Sharpe and Lintner. The model uses equilibrium risk premiums to provide a neutral reference point for expected returns, generating a market-capitalisation-weighted-portfolio and then incorporating subjective views that tilts in the direction of assets favored by the investor to enable the generation of alpha. The Black-Litterman models assumes does not assume the model is always at CAPM equilibrium, but any shift away from this equilibrium will experience pressure from the market to revert. Furthermore, the model allows the investor to have as many, or as few, views as they wish on either an absolute or relative basis. \n",
    "\n",
    "The issue with the CAPM model and minimum-variance portfolio decribed by Markowitz is that small tweaks in the values could lead to significant rebalancing of the portfolio. The Markowitz framework effectively takes the risk-free return as the alternative benchmark. \n",
    "\n",
    "\n",
    "There functional x numbers of steps we need to follow:\n",
    "\n",
    "- We need to asign weights to our portfolio based on a relevant benchmark or methodology. \n",
    "- We need to construct prior returns for each of our assets based on their relative weights\n",
    "- We need to construct a matrix of investor views to cause our assets to diverge from the initial weights \n",
    "- We combine the market implied returns and investor views to get the posterior distribution\n",
    "- We then generate our new allocations. \n",
    "\n",
    "We will use a 60/40 US portfolio as our benchmark we will use the reference ETFs SPY to proxy the equitiy portion of the portfolio and the fixed income portion will be represented via AGG. We will use 11 ETFs to represent the GICS sectors and we will weight these assets according to the market weights of the SPY reference index, and we will break down the fixed income allocation into short and long dated sectors with the appropriate weights according to AGG benchmark.\n",
    "\n",
    "While the Markowitz min-variance optimisation is designed to use discrete returns, the Black-Litterman model is based on log return. \n",
    "\n",
    "$$\n",
    "\n",
    "R_{i} = log(1 + \\frac{P_{i+1}}{P_i})\n",
    "\n",
    "$$\n",
    "\n",
    "Whereby $ R_{d} = \\frac{S_{i+1} - S_{i}}{S_i} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 1 - Default Weights from S&P 500 per GICs Sector\n",
    "\n",
    "| Sector                  | Weights  |\n",
    "| :---------------------: | :---:    |\n",
    "| Information Technology  | 30.37%   |\n",
    "| Financials              | 12.95%   |\n",
    "| Health Care             | 12.37%   |\n",
    "| Consumer Discretionary  | 9.60%    |\n",
    "| Communication           | 8.99%    |\n",
    "| Industrials             | 8.44%    |\n",
    "| Consumer Staples        | 6.16%    |\n",
    "| Energy                  | 3.66%    |\n",
    "| Utilities               | 2.51%    |\n",
    "| Real Estate             | 2.39%    |\n",
    "| Materials               | 2.28%    |\n",
    "| Cash and/or Derivatives | 0.29%    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Reverse Optimisation & Prior Returns\n",
    "\n",
    "Now that we have the optimal weights according to our equilibrium returns we are going to undertake a reverse optimisation of the weights to arrive at the returns vector for our sectors that would generate these weights. To solve this reverse optimisation we need to set up our problem. \n",
    "\n",
    "$$\n",
    "arg \\min_{\\omega} \\omega'\\pi - \\lambda\\omega'\\Sigma\\omega\n",
    "$$\n",
    "\n",
    "- $\\omega$: a vector of our sector weights\n",
    "- $\\pi$: a vector of our equilibrium returns\n",
    "- $\\lambda$: a scalar factor for risk-aversion\n",
    "- $\\Sigma$: covariance matrix for our returns\n",
    "\n",
    "Initially we will solve an unconstrained mean-variance and then will introduce constraints for a more robust solution. We take the derivative with respect to $w$ to get the following equation: \n",
    "\n",
    "$$\n",
    "\\pi - 2 \\lambda \\Sigma w = 0\n",
    "$$\n",
    "\n",
    "We re-arrange the equation for both $\\pi$ and $w$ to get the implied equilibrium return from our market weights and optimal weights under our model:\n",
    "\n",
    "$$\n",
    "\\pi^{*} = 2 \\lambda \\Sigma w\n",
    "$$\n",
    "\n",
    "$$\n",
    "w^{*} = \\frac{1}{2 \\lambda} \\Sigma^{-1} \\pi\n",
    "$$\n",
    "\n",
    "We can now calculate the implied market returns from our model based upon the market weights provided by the corresponding ETF proxies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = tabulate((annualised_implied_excess_returns_vector.map('{:,.2f}%'.format)), headers='keys', tablefmt='pipe')\n",
    "\n",
    "# print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 2 - Implied Equilibrium Returns per GICs Sector (Annualised)\n",
    "\n",
    "|                        | Implied Return   |\n",
    "|:-----------------------|:-----------------|\n",
    "| Energy                 | 7.45%            |\n",
    "| Materials              | 7.28%            |\n",
    "| Industrials            | 7.12%            |\n",
    "| Consumer Discretionary | 6.70%            |\n",
    "| Consumer Staples       | 4.88%            |\n",
    "| Health Care            | 5.47%            |\n",
    "| Financials             | 7.25%            |\n",
    "| Information Technology | 8.06%            |\n",
    "| Communication Services | 6.09%            |\n",
    "| Utilities              | 4.18%            |\n",
    "| Real Estate            | 6.06%            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Formulating Views\n",
    "\n",
    "Naturally if we plug these implied returns back into our formula for the optimal weights we will arrive back at the market weights we initially used to derive the returns. The Black-Litterman model only suggests a deviation from the market returns once we have formulated views on assets. We need to specify our views on the market, which may or may not, clash with the reference market distribution. \n",
    "\n",
    "Views are expressed in either absolute or relative terms. We will define the following views:\n",
    "\n",
    "- View 1: Energy will an absolute excess return 7%\n",
    "- View 2: Information Technology will outperform Financials by 25bps on an excess return basis. \n",
    "- View 3: Subset defensive sectors (Consumer Staples & Utilities) will outperform the subset cyclical sectors (Consumer Discretionary & Information Technology) by 1%. \n",
    "\n",
    "Despite the fact that we have an absolute view and a relative view, this does not necessarily suggest that we should positively allocate to the asset that we expect to either return positively or outperform the other asset. We need to compare our prediction against the implied return from the existing market weights and determine whether our view is producing either a positive or negative deviation from the implied market return, and only in the event of a positive deviation would we then increase our potential allocation. In the case of our first view we have an implied excess return for Energy at 7.45%, and therefore an excess return of 2% would represent a decrease of 45bps. We should see a reduction in the market allocation to this sector. \n",
    "\n",
    "Similarly although we are predicting an outperform of Information Technology over Financials we need to evaluate what the existing out-or-underperformance between the two sectors. Once again we can see that the Information Technology sector currently outperforms Financials by 81bps. The prediction of 25bps would represent another negative bias towards Information Technolgoy and should see an increase in the allocation to Financials correspondingly. \n",
    "\n",
    "The calculation is more complicated when we evaluate multiple sectors against each other because of the interlinking allocation dynamics. We will need to form two mini portfolios with each sector given proportional weighting to it's market weights and then compare the performance of two portfolios to determine whether our relative prediction will generate a positive or negative bias towards the existing allocation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig. 3 Comparing Subset Sector Implied Excess Return\n",
    "|                        | Market Weight   | Relative Subset Weight  | Weight Excess Return |\n",
    "|:-----------------------|:---------------:|:-----------------------:|:-------------------:|\n",
    "| Consumer Staples       | 6.16%           | 71.05%                  | 4.76%               |\n",
    "| Utilities              | 2.51%           | 28.95%                  | 1.21%               |\n",
    "|                        |                 | Total                   | 5.97%               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                        | Market Weight   | Relative Subset Weight  | Weight Excess Return |\n",
    "|:-----------------------|:---------------:|:-----------------------:|:-------------------:|\n",
    "| Information Technology | 30.37%          | 75.98%                  | 6.12%               |\n",
    "| Consumer Discretionary | 9.60%           | 24.02%                  | 1.60%               |\n",
    "|                        |                 | Total                   | 7.72%               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the current subset defensive sectors are significantly under performing the cycling sectors, and if we are confident in our view we should see a noticeable deviation in our new portfolio allocations compared to the existing market portfolio. \n",
    "\n",
    "Now that we have formulated our views on the market and what we expect to see from our allocations. Let us move onto the practical implementation of the views into our model mathemtically "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4 Views Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Q$ corresponds to our views vector. We have 3 views so we will generate a $k \\times 1$ vector where k is the number of views. Each view contains a degree of uncertainty about our confidence in the view and this is represented by $ \\epsilon $. This term $\\epsilon$ is a random, unknown, independent, normally distributed error term with a distribution as follows:\n",
    "\n",
    "$$\n",
    "\\epsilon \\sim \\mathcal{N}(0, \\Omega)\n",
    "$$\n",
    "\n",
    "The error term itself does not enter our Black Litterman model but the difference between the error terma and the expected value of 0 will enter the model. The variance represents the uncertainty, and therefore the larger the variance the greater the uncertainty. \n",
    "\n",
    "The expressed views in our $Q$ vector is then mapped to the corresponding asset by the matrix $P$. Each expressed view generates a $1 \\times N$ row vector and ultimately gives us a $K \\times N$ matrix. The difference between an absolute view and a relative view in our matrix is defined by the row total for each option. Relative views will sum to 0 on each row, while Absolute views will not. In the case of our first row we have an absolute view on the 1st asset. As a result the row vector will be defined as below:\n",
    "\n",
    "$$\n",
    "P_1 = \\begin{bmatrix}\n",
    "    1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The second view is a relative view on two assets so the nominally outpeforming asset will recieve a positive weighting while the underperforming asset will recieve a negative rating, however the row must sum to 0. We will apply these weights to the 7th and 8th assets. \n",
    "\n",
    "$$\n",
    "P_2 \\begin{bmatrix}\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & -1 & 1 & 0 & 0 & 0 \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In the event that we are comparing muliple assets for a relative view then the situation is slightly more complicated. The row still needs to sum up to 0 but we need away to assign values to 4 assets rather than just 2. Satchell and Scowcroft demonstrate the use of an equal weighting scheme, whiile Idzorek uses a market capitalisation approach. Following Satchell and Scowcroft approach leads to the simplest vector by simply applying a positive 2/N and a negative 2/N value to outperforming and underperforming assets respectively. \n",
    "\n",
    "$$\n",
    "P_3 = \\begin{bmatrix}\n",
    "    0 & 0 & 0 & -0.5 & 0.5 & 0 & 0 & -0.5 & 0 & 0.5 & 0\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This is the simplest formulation for our problem but because it ignores the portfolio weights and therefore can lead to more extreme rebalancing on smaller weighted sectors. Idzorek proposes that we introduce the relative subset weight for our sectors instead to mitigate this overreaction in re-allocation and given we already calculate them above it's fairly simple to substitute them in and get our final views matrix. \n",
    "\n",
    "$$\n",
    "P = \\begin{bmatrix}\n",
    "    1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "    0 & 0 & 0 & 0 & 0 & 0 & -1 & 1 & 0 & 0 & 0 \\\\\n",
    "    0 & 0 & 0 & -0.24 & 0.71 & 0 & 0 & -0.76 & 0 & 0.29 & 0\n",
    "    \\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: scalar and covariance matrix of the error term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Views are expressed on the expected returns $P_u$ and have the following distribution:\n",
    "\n",
    "$$\n",
    "P_{u} \\sim \\mathcal{N}(v, \\Omega)\n",
    "$$\n",
    "\n",
    "and our covariance matrix of error terms is $ \\Omega = diag(P(\\tau \\Sigma) P^{'}) $\n",
    "\n",
    "The term $\\tau$ is a scalar that controls the value assigned to the uncertainty to the combined returns distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the implied equity adjusted returns using Bayes Thereom via Meucci (2010)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mu_{BL} = \\pi + \\tau \\Sigma P^{'} (\\tau P \\Sigma P^{'} + \\Omega)^{-1}(v - P\\pi)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the posterior returns for our sectors we can now obtain the optimal weights for this new distribution. Our new optimisation problem follows:\n",
    "\n",
    "$$\n",
    "arg \\min_{\\omega} \\omega'\\mu_{BL} - \\lambda\\omega'\\Sigma\\omega\n",
    "$$\n",
    "\n",
    "\n",
    "As we saw earlier in an unconstrained problem this gives us the neat solution:\n",
    "\n",
    "$$\n",
    "w^{*} = \\frac{1}{2 \\lambda} \\Sigma^{-1} \\mu_{BL}\n",
    "$$\n",
    "\n",
    "We can now compare across all our two return distributions and subsequent changes in market allocation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fig 4. Comparing the change in sector return and weights before and after the introduction of views\n",
    "\n",
    "|                        | Adjusted Return   | Implied Return   | Adj. - Impl. Return   | Adjusted Weights   | Equilibrium Weights   | Adj. - Eq. Weights   |\n",
    "|:-----------------------|:------------------|:-----------------|:----------------------|:-------------------|:----------------------|:---------------------|\n",
    "| Energy                 | 6.77%             | 7.45%            | -0.67%                | 4.91%              | 3.66%                 | 1.25%                |\n",
    "| Materials              | 6.39%             | 7.28%            | -0.89%                | 2.26%              | 2.28%                 | -0.02%               |\n",
    "| Industrials            | 6.16%             | 7.12%            | -0.97%                | 8.36%              | 8.44%                 | -0.08%               |\n",
    "| Consumer Discretionary | 5.46%             | 6.70%            | -1.24%                | -0.25%             | 9.60%                 | -9.85%               |\n",
    "| Consumer Staples       | 4.85%             | 4.88%            | -0.04%                | 34.96%             | 6.16%                 | 28.80%               |\n",
    "| Health Care            | 4.88%             | 5.47%            | -0.58%                | 12.25%             | 12.37%                | -0.12%               |\n",
    "| Financials             | 6.33%             | 7.25%            | -0.92%                | 5.08%              | 12.95%                | -7.87%               |\n",
    "| Information Technology | 6.11%             | 8.06%            | -1.95%                | 6.91%              | 30.37%                | -23.46%              |\n",
    "| Communication Services | 5.36%             | 6.09%            | -0.73%                | 8.90%              | 8.99%                 | -0.09%               |\n",
    "| Utilities              | 4.60%             | 4.18%            | 0.42%                 | 14.27%             | 2.51%                 | 11.76%               |\n",
    "| Real Estate            | 5.69%             | 6.06%            | -0.36%                | 2.37%              | 2.39%                 | -0.02%               |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjusted return after incorporating out views are consistently, with the exception of utilities, lower than the implied marke returns from our model. This is intuitively inline with our views, we expected energy to perform worse on an absolute basis, the gap between Financials and Information technology has significantly shrink and we expected for our defensive subsectors to perform better than our growth sectors. Curiously this has manifesting in a significant reduction in predicted returns for our Information Technology and Consumer Discretionary, while Consumer Staples and Utilities maintain and slightly overperform respectively. Naturally, this new adjusted return vector does lead to significant reblancing in our sectors specified in Views 3 and 2, but we also seem minimal tweaks of the other sectors in the portfolio. This is confirmation of the in-built theory within the Black-Litterman model that deviating from the market portfolio is only appropraite when there is a mismatch between market expectations and the current equilibrium. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table = tabulate(combined_df.applymap(lambda x: f\"{x:.2%}\"), headers='keys', tablefmt='pipe')\n",
    "\n",
    "# print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Adding constraints to our optimisation\n",
    "\n",
    "Now that we have our default Black-Litterman model defined and initailised we can move onto producing a more robust solution to our portfolio construction. Currently we are performing unconstrained opitmision but in reality investors are commonly constrained. We can add fairly common and investor constraints for no leverage and no short positions. Currently in our unconstrained portfolio we are taking a small short position in Consumer Discretionary which we want to eliminate for a long only portfolio. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Optimising for Sharpe Ratio\n",
    "\n",
    "2.7 Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------- Python -----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql('portfolio_data', con=engine)\n",
    "\n",
    "# # set date as index\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "df.rename(columns={\n",
    "    'IYE': 'Energy',\n",
    "    'IYM': 'Materials',\n",
    "    'IYJ': 'Industrials',\n",
    "    'IYC': 'Consumer Discretionary',\n",
    "    'IYK': 'Consumer Staples',\n",
    "    'IYH': 'Health Care',\n",
    "    'IYF': 'Financials',\n",
    "    'IYW': 'Information Technology',\n",
    "    'IYZ': 'Communication Services',\n",
    "    'IDU': 'Utilities',\n",
    "    'IYR': 'Real Estate',\n",
    "    '^IRX':'3M TB'\n",
    "\n",
    "    }, inplace=True)\n",
    "\n",
    "three_month_tbill = df['3M TB'] / 252\n",
    "\n",
    "# consistent ordering\n",
    "df = df[['Energy', 'Materials', 'Industrials', 'Consumer Discretionary', 'Consumer Staples', 'Health Care', 'Financials', 'Information Technology', \n",
    "         'Communication Services', 'Utilities', 'Real Estate']]\n",
    "         \n",
    "\n",
    "# calculate simple returns\n",
    "simple_returns = df.pct_change()\n",
    "\n",
    "# subtract the 3m t bill daily rate\n",
    "excess_returns = simple_returns.sub(three_month_tbill, axis=0)\n",
    "\n",
    "# # calculate log returns returns\n",
    "log_returns = np.log(1 + simple_returns).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlackLittermanModel:\n",
    "    def __init__(self, equilibrium_weights, log_returns, risk_aversion, views_mapping_matrix, views_matrix, tau=0.025):\n",
    "        self._equilibrium_weights = equilibrium_weights\n",
    "        self._log_returns = log_returns\n",
    "        self._risk_aversion = risk_aversion\n",
    "        self._tau = tau\n",
    "        self._covariance_matrix = self._calculate_covariance_matrix()\n",
    "        self._views_mapping_matrix = views_mapping_matrix\n",
    "        self._views_matrix = views_matrix\n",
    "\n",
    "    # TODO: private methods\n",
    "    def _calculate_covariance_matrix(self):\n",
    "        # calculate the vols\n",
    "        volatilities_array = self._log_returns.std()\n",
    "\n",
    "        # calculate correlation\n",
    "        correlation_coefficients = self._log_returns.corr()\n",
    "\n",
    "        # create the diagonal vol matrix (vol on the diagonal, zeros elsewhere)\n",
    "        std_diag_vol_matrix  = np.diag(volatilities_array)\n",
    "\n",
    "        # compute the covariance matrix\n",
    "        covariance_matrix = std_diag_vol_matrix @ correlation_coefficients.values @ std_diag_vol_matrix\n",
    "\n",
    "        # pass the headers from log return \n",
    "\n",
    "        covariance_matrix = pd.DataFrame(\n",
    "            covariance_matrix,\n",
    "            columns = self._log_returns.columns,\n",
    "            index = self._log_returns.columns,\n",
    "        )\n",
    "\n",
    "        return covariance_matrix\n",
    "    \n",
    "    def calculate_views_adjusted_returns(self):\n",
    "        # we need implied equity returns and omega\n",
    "        implied_returns_vector = self.calculate_implied_equilibrium_returns().values\n",
    "\n",
    "        omega = self.calculate_uncertainty_views_matrix()\n",
    "\n",
    "        # we have three terms for the np.dot product\n",
    "        tau_sigma_transpose_p = self._tau * (self._covariance_matrix.values @ self._views_mapping_matrix.T)\n",
    "\n",
    "        inverse_middle_term = np.linalg.inv((self._views_mapping_matrix @ tau_sigma_transpose_p) + omega)\n",
    "\n",
    "        view_minus_p = (self._views_matrix - (self._views_mapping_matrix @ implied_returns_vector))\n",
    "\n",
    "        views_adjusted_returns_vector = implied_returns_vector + ((tau_sigma_transpose_p @ inverse_middle_term) @ view_minus_p)\n",
    "\n",
    "        # convert to dataframe for consistency\n",
    "        views_adjusted_returns = pd.DataFrame(views_adjusted_returns_vector, columns=[\"Adjusted Return\"], index=self._log_returns.columns)\n",
    "\n",
    "        return views_adjusted_returns\n",
    "    \n",
    "    # calculate the covariance of the error terms aka omega\n",
    "    def calculate_uncertainty_views_matrix(self):\n",
    "        # you extract the diagonal and then convert to a diagonal matrix with zeros\n",
    "        omega = np.diag(((self._views_mapping_matrix @ (self._tau * self._covariance_matrix)) @ self._views_mapping_matrix.T))\n",
    "        \n",
    "        return np.diag(omega)\n",
    "\n",
    "    \n",
    "    def calculate_implied_equilibrium_returns(self):\n",
    "        implied_returns_vector = self._risk_aversion * (self._covariance_matrix @ self._equilibrium_weights)\n",
    "\n",
    "        implied_returns = pd.DataFrame(implied_returns_vector, columns=[\"Implied Return\"], index=self._log_returns.columns)\n",
    "\n",
    "        return implied_returns\n",
    "    \n",
    "    def calculate_unconstrained_mv_optimisation(self):\n",
    "        # invert the covariance matrix\n",
    "        inv_cov_matrix = np.linalg.inv(self._covariance_matrix)\n",
    "\n",
    "        # calculate adjusted returns\n",
    "        adjusted_returns = self.calculate_views_adjusted_returns().values\n",
    "\n",
    "        # obtain weights\n",
    "        optimal_weights = self._risk_aversion * np.dot(inv_cov_matrix, adjusted_returns)\n",
    "\n",
    "        # # normalise the sum of weights to 1\n",
    "        optimal_weights /= np.sum(optimal_weights)\n",
    "\n",
    "        # convert to dataframe for consistency\n",
    "        optimal_weights = pd.DataFrame(optimal_weights, columns=[\"Adjusted Weights\"], index=self._log_returns.columns)\n",
    "\n",
    "        return optimal_weights\n",
    "\n",
    "    \n",
    "    # attributes\n",
    "    # tau\n",
    "    @property\n",
    "    def tau(self):\n",
    "        return self._tau\n",
    "\n",
    "    @tau.setter\n",
    "    def tau(self, value):\n",
    "        self._tau = value\n",
    "\n",
    "    # risk aversion \n",
    "    @property\n",
    "    def risk_aversion(self):\n",
    "        return self._risk_aversion\n",
    "\n",
    "    @risk_aversion.setter\n",
    "    def risk_aversion(self, value):\n",
    "        self._risk_aversion = value\n",
    "\n",
    "    @property\n",
    "    def covariance_matrix(self):\n",
    "        return self._covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the class\n",
    "equilibrium_weights = pd.Series({\n",
    "    'Energy': 0.0366,\n",
    "    'Materials': 0.0228,\n",
    "    'Industrials': 0.0844,\n",
    "    'Consumer Discretionary': 0.0960,\n",
    "    'Consumer Staples': 0.0616,\n",
    "    'Health Care': 0.1237,\n",
    "    'Financials': 0.1295,\n",
    "    'Information Technology': 0.3037,\n",
    "    'Communication Services': 0.0899,\n",
    "    'Utilities': 0.0251,\n",
    "    'Real Estate': 0.0239\n",
    "})\n",
    "\n",
    "risk_aversion_dict = pd.Series({\n",
    "    # in order of increasing aversion\n",
    "    'Kelly': 0.01,\n",
    "    'Market': 2.24,\n",
    "    'Trustee': 6\n",
    "})\n",
    "\n",
    "# view adjusted returns with defined views\n",
    "k = 3\n",
    "n = 11\n",
    "\n",
    "#  these are annual views so we need to divide by 252 to make them daily\n",
    "Q = np.array([0.07, 0.0025, 0.01]).reshape(-1, 1) / 252\n",
    "\n",
    "P = np.zeros((k, n))\n",
    "\n",
    "# bl_model.calculate_views_adjusted_returns()\n",
    "# first view\n",
    "P[0, 0] = 1\n",
    "# second view\n",
    "P[1, 6] = -1\n",
    "P[1, 7] = 1\n",
    "# third view\n",
    "P[2, 3] = -0.24\n",
    "P[2, 4] = 0.71\n",
    "P[2, 7] = -0.76\n",
    "P[2, 9] = 0.29\n",
    "\n",
    "bl_model = BlackLittermanModel(equilibrium_weights, log_returns, risk_aversion_dict['Market'], P, Q)\n",
    "\n",
    "# bl_model.calculate_implied_equilibrium_returns()\n",
    "\n",
    "# bl_model.calculate_views_adjusted_returns().mul(100).mul(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3z/lz8knlfn5ys693qpn6bnjb440000gn/T/ipykernel_70218/1767232078.py:22: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  combined_df.applymap(lambda x: f\"{x:.2%}\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adjusted Return</th>\n",
       "      <th>Implied Return</th>\n",
       "      <th>Adj. - Impl. Return</th>\n",
       "      <th>Adjusted Weights</th>\n",
       "      <th>Equilibrium Weights</th>\n",
       "      <th>Adj. - Eq. Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>6.77%</td>\n",
       "      <td>7.45%</td>\n",
       "      <td>-0.67%</td>\n",
       "      <td>4.91%</td>\n",
       "      <td>3.66%</td>\n",
       "      <td>1.25%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Materials</th>\n",
       "      <td>6.39%</td>\n",
       "      <td>7.28%</td>\n",
       "      <td>-0.89%</td>\n",
       "      <td>2.26%</td>\n",
       "      <td>2.28%</td>\n",
       "      <td>-0.02%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industrials</th>\n",
       "      <td>6.16%</td>\n",
       "      <td>7.12%</td>\n",
       "      <td>-0.97%</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>8.44%</td>\n",
       "      <td>-0.08%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer Discretionary</th>\n",
       "      <td>5.46%</td>\n",
       "      <td>6.70%</td>\n",
       "      <td>-1.24%</td>\n",
       "      <td>-0.25%</td>\n",
       "      <td>9.60%</td>\n",
       "      <td>-9.85%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Consumer Staples</th>\n",
       "      <td>4.85%</td>\n",
       "      <td>4.88%</td>\n",
       "      <td>-0.04%</td>\n",
       "      <td>34.96%</td>\n",
       "      <td>6.16%</td>\n",
       "      <td>28.80%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health Care</th>\n",
       "      <td>4.88%</td>\n",
       "      <td>5.47%</td>\n",
       "      <td>-0.58%</td>\n",
       "      <td>12.25%</td>\n",
       "      <td>12.37%</td>\n",
       "      <td>-0.12%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Financials</th>\n",
       "      <td>6.33%</td>\n",
       "      <td>7.25%</td>\n",
       "      <td>-0.92%</td>\n",
       "      <td>5.08%</td>\n",
       "      <td>12.95%</td>\n",
       "      <td>-7.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Information Technology</th>\n",
       "      <td>6.11%</td>\n",
       "      <td>8.06%</td>\n",
       "      <td>-1.95%</td>\n",
       "      <td>6.91%</td>\n",
       "      <td>30.37%</td>\n",
       "      <td>-23.46%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communication Services</th>\n",
       "      <td>5.36%</td>\n",
       "      <td>6.09%</td>\n",
       "      <td>-0.73%</td>\n",
       "      <td>8.90%</td>\n",
       "      <td>8.99%</td>\n",
       "      <td>-0.09%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Utilities</th>\n",
       "      <td>4.60%</td>\n",
       "      <td>4.18%</td>\n",
       "      <td>0.42%</td>\n",
       "      <td>14.27%</td>\n",
       "      <td>2.51%</td>\n",
       "      <td>11.76%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Real Estate</th>\n",
       "      <td>5.69%</td>\n",
       "      <td>6.06%</td>\n",
       "      <td>-0.36%</td>\n",
       "      <td>2.37%</td>\n",
       "      <td>2.39%</td>\n",
       "      <td>-0.02%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Adjusted Return Implied Return Adj. - Impl. Return  \\\n",
       "Energy                           6.77%          7.45%              -0.67%   \n",
       "Materials                        6.39%          7.28%              -0.89%   \n",
       "Industrials                      6.16%          7.12%              -0.97%   \n",
       "Consumer Discretionary           5.46%          6.70%              -1.24%   \n",
       "Consumer Staples                 4.85%          4.88%              -0.04%   \n",
       "Health Care                      4.88%          5.47%              -0.58%   \n",
       "Financials                       6.33%          7.25%              -0.92%   \n",
       "Information Technology           6.11%          8.06%              -1.95%   \n",
       "Communication Services           5.36%          6.09%              -0.73%   \n",
       "Utilities                        4.60%          4.18%               0.42%   \n",
       "Real Estate                      5.69%          6.06%              -0.36%   \n",
       "\n",
       "                       Adjusted Weights Equilibrium Weights Adj. - Eq. Weights  \n",
       "Energy                            4.91%               3.66%              1.25%  \n",
       "Materials                         2.26%               2.28%             -0.02%  \n",
       "Industrials                       8.36%               8.44%             -0.08%  \n",
       "Consumer Discretionary           -0.25%               9.60%             -9.85%  \n",
       "Consumer Staples                 34.96%               6.16%             28.80%  \n",
       "Health Care                      12.25%              12.37%             -0.12%  \n",
       "Financials                        5.08%              12.95%             -7.87%  \n",
       "Information Technology            6.91%              30.37%            -23.46%  \n",
       "Communication Services            8.90%               8.99%             -0.09%  \n",
       "Utilities                        14.27%               2.51%             11.76%  \n",
       "Real Estate                       2.37%               2.39%             -0.02%  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# returns\n",
    "annualised_adjusted_excess_returns_vector = bl_model.calculate_views_adjusted_returns().mul(252)\n",
    "annualised_implied_excess_returns_vector = bl_model.calculate_implied_equilibrium_returns().mul(252)\n",
    "\n",
    "# weights\n",
    "adjusted_weights_vector = bl_model.calculate_unconstrained_mv_optimisation()\n",
    "equilibrium_weights_vector = pd.DataFrame(equilibrium_weights, columns=['Equilibrium Weights'])\n",
    "\n",
    "combined_df = pd.concat([annualised_adjusted_excess_returns_vector, \n",
    "                         annualised_implied_excess_returns_vector,\n",
    "                         adjusted_weights_vector,\n",
    "                         equilibrium_weights_vector], axis=1)\n",
    "\n",
    "\n",
    "# delta weights and return\n",
    "combined_df['Adj. - Impl. Return'] = combined_df['Adjusted Return'] - combined_df['Implied Return']\n",
    "combined_df['Adj. - Eq. Weights'] = combined_df['Adjusted Weights'] - combined_df['Equilibrium Weights']\n",
    "\n",
    "# column order\n",
    "combined_df = combined_df[['Adjusted Return', 'Implied Return', 'Adj. - Impl. Return', 'Adjusted Weights', 'Equilibrium Weights', 'Adj. - Eq. Weights']]\n",
    "\n",
    "combined_df.applymap(lambda x: f\"{x:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliography\n",
    "\n",
    "Black, F. and Litterman, R. 1990. Asset Allocation: Combining Investors Views with Market Equilibrium. Goldman Sachs Fixed Income Research working paper\n",
    "\n",
    "Black, F. and Litterman, R. 1991. Global Asset Allocation with Equities, Bonds, and Currencies. Goldman Sachs Fixed Income Research working paper\n",
    "\n",
    "Black, F. and Litterman, R. 1992. Global Portfolio Optimization.Financial Analysts Journal, 28-43.\n",
    "\n",
    "Idzorek, T.M. 2002. A step-by-step guide to Black-Litterman model. Incorporating user-specified confidence levels. Working Paper, 2-11.\n",
    "\n",
    "Satchell, S. and Scowcroft, A. (2000). “A Demystification of the Black-Litterman Model: Managing Quantitative and Traditional Construction.” Journal of Asset Management, September, 138-150.\n",
    "\n",
    "Markowitz, H., 1952. Portfolio Selection. The Journal of Finance, 7(1): 77-91."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
